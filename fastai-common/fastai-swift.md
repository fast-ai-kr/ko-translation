# 딥러닝에 Swift를 도입하는 fast.ai
> 작성일: 2019년 3월 06일, 작성자: Jeremy Howard

오늘, [TensorFlow 데브서밋](https://www.tensorflow.org/dev-summit)에서 다음으로 열리는 두 개의 강의에서 [TensorFlow를 위한 Swift (S4TF)](https://github.com/tensorflow/swift) 내용이 다뤄질것임을 발표했습니다. 이 강의들은 Swift의 창시자인 [Chris Lattner](https://en.wikipedia.org/wiki/Chris_Lattner)와 함께 가르치게 될 것이고, 현재의 [fastai](https://docs.fast.ai/) 라이브러리와 똑같은것을 S4TF를 사용해서 구현하는 첫 걸음을 떼는 방법을 배우게 될 것입니다. Swift로 프로그래밍 하는 방법을 보여드릴 것이고, S4TF를 어떻게 사용하고 확장하는지에 대한 설명도 드릴것입니다.

지난 달 Swift가 [고성능 수치계산](https://www.fast.ai/2019/01/10/swift-numerics/)을 위해서 사용될 수 있음을 보여드렸습니다 (그 내용에 대한 글에는 Swift가 무엇인지에 대한 배경지식과 Swift가 위대한 언어인 이유를 설명하고 있으니 아직 읽어보지 않으셨다면 확인해보시기 바랍니다). 이 주제에 대한 제 연구를 통해서, Swift가 수치형 라이브러리를 사용해서 손으로 직접 튜닝한 수준의 성능이 가능함을 발견했습니다. 하지만, 이것을 말씀드리고 싶습니다: "머신러닝 모델을 학습시키는것과 같은 수치형 프로그래밍에 대해서 Swift를 사용하는것은 많은 사람들이 관심을 쏟고 있는 분야가 아닙니다. 해당 주제에 대해서는 매우 적은 정보만이 존재합니다"

그런데, 저희는 왜 지금 Swift를 받아들이려고 할까요? 그 이유는 S4TF가 적어도 제가 생각하기에, 애초에 성능을 위해 디자인되었고 널리 사용되는 언어로써, [미분가능한 프로그래밍(differentiable programming)](https://techburst.io/deep-learning-est-mort-vive-differentiable-programming-5060d3c55074)을 [심각하게](https://github.com/tensorflow/swift/blob/master/docs/DesignOverview.md) 포함하려는 첫 번째 노력이기 때문입니다.

## fast.ai 에서 Swift를 받아들일 계획

Python을, PyTorch, 그리고 fastai의 조합은 매우 잘 동작하고, 저희 커뮤니티도 그 부분을 좋아합니다. 현재 저희는 PyTorch에 대해서 fastai를 사용하는 여러가지 진행중인 프로젝트가 있습니다. 그 프로젝트들은 곧 출간된 책, 여러가지 새로운 소프트웨어 기능, 그리고 앞으로 있을 강의에 대한 여러 컨텐츠에 대한것을 포함합니다. 이 스택은 여전히 교육 그리고 개발에 대한 우리의 주된 포커스가 될 것입니다.

S4TF는 매우 시기상조 입니다. 모든 딥러닝 프로젝트를 Swift로 바꾸는것을 결코 추천하지는 않습니다. 현재, 대부분의 것들이 잘 동작하지 않습니다. 대부분의 계획은 심지어 시작조차 하지 않았습니다. 많은 분들에게는, S4TF 프로젝트 전체를 건너뛰기에 괜찮은 이유일 것입니다.

하지만, 제 생각엔, 이것이 바로 시도해야하는 이유라고 생각합니다. 저는 성공적이게 될 것이라고 확신하는 프로젝트의 초반에 연관되는것을 좋아하고, fastai 커뮤니티가 연관될 수 있게끔 도움을 주려고 합니다. 그게 바로 PyTorch에 대해서 우리가 해온 일로, PyTorch의 사전-릴리즈(pre-release) 버전을 fastai 강의에 포함시켰었습니다. 이렇게, 프로젝트 초기에 발을 담그고 싶은 사람들은 그 프로젝트 개발에 큰 영향력을 가질 수 있고, 그들 스스로 금새 "인사이더"가 되어 있는것을 발견하게 됩니다!

저는 지는 20년간 진정으로 위대한 수치형 프로그래밍 언어를 고대해왔습니다. 따라서 저에게 있어서 Swift의 가능성은 그 언어에 대한 엄청난 흥분이 되었습니다. 학생 여러분은 S4TF에서 아직 구현되지 않은 여러가지 프로젝트에서 원하는것을 골라서, 해당 기능에 대한 구현 및 테스트에 대한 PR을 보낼 수 있는 열린 기회를 가질 수 있습니다.

## Python: 무엇이 빠졌는가

지난 3년간, fastai 강의에서 여러가지 딥러닝 라이브러로 [바꿔왔었습니다](https://www.fast.ai/2017/09/08/introducing-pytorch-for-fastai/): Theano, TensorFlow, Keras, Python, 그리고 저희의 고유한 fastai 라이브러리가 그것입니다. 하지만, 이 모든것들은 한가지의 공통점을 가지고 있습니다: 이들 모두 Python 라이브러리라는 것입니다. 그 이유는 Python이 오늘날 거의 모든 딥러닝 연구, 교육, 상업에 사용되는 언어이기 때문입니다. 딥러닝 현역 기술자가 되기위해서 Python 이외의 언어를 사용한다는 것은 상호연결된 거대한 라이브러리 생태계를 포기한다는 것을 의미합니다. 또는 이종 언어간 통신하기 위한 투박한 메커니즘을 통해서 Python 라이브러리를 사용해야함을 의미합니다.

하지만, Python은 빠른 속도를 위해 설계되지 않았고, 안정성을 위해 설계되지도 않았습니다. 대신, 쉽고 유연함을 위해 설계된 언어 입니다. "순수 Python" 코드를 사용해서 성능 문제를 해결하기 위해서는 numpy, Python, TensorFlow와 같이 (일반적으로 C, C++)다른 언어로 작성된 라이브러리를 대안으로 사용해야만 합니다. 타입(Type) 안정성 문제를 해결하기 위해서, Python의 최근 버전은 타입 어노테이션(type annotation)을 추가하여 선택적으로 프로그래머가 타입을 명시할 수 있도록 하였습니다. 하지만, Python의 타입 시스템은 많은 타입 종류와 그들간의 관계를 표현하기에 충분치 않고, 자동화된 타이핑을 하지 못하고, 컴파일시에 모든 타입을 안정적으로 체크하는 것이 불가능 합니다. 따라서, Python에서 타입을 사용한다는것은 많은 추가적인 코드를 요구함에도 불구하고 다른 언어가 제공하는 타입 안정성의 수준에는 한참 미치지 못합니다.

모든 Python의 수치형 프로그래밍의 중심에 있는 C/C++ 라이브러리는 연구자와, 교육자 모두에게 문제를 가지고 있습니다. 연구자는 손쉽게 근본적인 코드를 변경하거나, 들여다보는것이 불가능한데, 그 이유는 이를 위해서 완전히 다른종류의 도구가 요구되기 때문입니다. 그리고, MKL 이나 cudnn과 같은 라이브러리의 경우, 근본적인 코드는 기계어에 최적화 되어 있습니다. 교육자는 학생들에게 특정 코드의 내부에서 무슨일이 벌어지는지 정확하게 학생들에게 보여주기가 어렵습니다. 개발자는 언어들의 사이를 넘나드는 부분의 코드를 프로파일리하고 최적화하기가 매우 어렵습니다. 또한 Python 자체가 언어 또는 라이브러리간의 코드를 적절히 최적화할 수 없습니다.

예를 들어서, 저희는 RNN(recurrent neural network) 구조와 정규화 계층의 여러 종류에 대해서 연구를 해오고 있습니다. 두 가지 경우 모두, PyTorch의 환상적인 새로운 [JIT 컴파일러](https://pytorch.org/docs/stable/jit.html)를 사용했음에도 불구하고 순수 CUDA C 구현의 성능 수준에 도달할 수 없었습니다.

작년 PyTorch 데브서밋에서, 저는 Soumith Chintala, Yangqing Jia, Noah Goodman, Chris Lattner와 함께 [패널](https://youtu.be/HnLNPHiyBBQ?t=4826)에 참가했었습니다. 패널 토의에서, 저는 이렇게 말했습니다: _"Python을 제외해고, PyTorch의 모든것이 마음에 듭니다."_. 그리고 Soumith에게 _"언젠가 'SwifTorch'를 마주할날이 올까요?"_ 질문했었습니다. 그 당시에는 제가 Swift에 대해서 이렇게 빨리 스스로 작업을 하게될것 이라는것을 몰랐었죠!

## 그러면, 이제부터 무엇을 해야하나?

결국에는 Python으로 작성된것들이 아래에 열거된 목록의 하나 또는 여러개를 다뤄야만 합니다:

- 순수 Python 코드로써 실행되는 것. 느린속도를 의미합니다.
- C 라이브러리의 래퍼(wrapper)가 되는것. 확장이 어렵고, 라이브러리간 최적화가 불가능하며 디버깅 및 프로파일링이 어렵다는것을 의미합니다.
- 다른 언어로 전환하는 것 (PyTorch가 TorchScript를, TensorFlow가 XLA를 사용하는것 처럼). 최종 타겟 언어로 작성하지 않고, 작성하는 언어와 실제 사용되는 언어 사이의 부조화를 다뤄야함을 의미합니다 (적어도 C 라이브러리를 사용했을때의 디버깅과 프로파일링과 동일 수준의).

반면에 Swift는 기저에 깔린 컴파일러 인프라인 LLVM과 매우 가깝게 연결되어 있습니다. 실제로 Chris Lattner는 전에 Swift를 "LLVM을 위한 문법적 설탕"이라고 묘사하기도 했었습니다. 그 의미는 Swift로 작성된 코드는 LLVM으로부터 제공되는 모든 성능 최적화 인프라의 이점을 고스란히 얻을 수 있다는 것입니다. 더욱이 Chris Lattner와 Jacques Pienaar는 최근 [MLIR라는 컴파일러 인프라 프로젝트](https://drive.google.com/file/d/1hUeAJXcAXwz82RXA5VtO5ZoH8cVQhrOK/view)를 만들었는데, 이 프로젝트는 S4TF의 능력을 매우 향상시킬 수 있는 가능성을 가지고 있습니다.

저희가 희망하는것은 딥러닝 스택의 모든 계층을 네트워크의 최상위 추상적 수준에서, 가장 낮은 수준인 RNN 셀 구현까지 Swift로 작성하게될 것이라는 것입니다. 이렇게 함으로써 얻을 수 있는 이점은 많습니다:

- 교육적 입장에서, 어떠한것도 미스테리하지 않습니다. 사용하는 코드의 모든것에 대해서 무슨일이 일어나는지 정확히 볼 수 있습니다.

- 연구적 입장에서, 한계가 없어집니다. 마음속으로 무엇을 생각하던지간에 그것을 구현하고, 최대의 속도로 실행할 수 있습니다.

- 개발적 입장에서, 언어가 도움이될 수 있습니다. 사용하는 편집기는 작성하는 코드를 깊게 이해하고, 지능적인 자동완성과 Tensor가 미스매치되는것과 같은 문제에 대한 경고를 발생시킬 수 있습니다. 그리고, 프로파일러는 일어나는 모든 단계를 보여주고, 성능적 문제를 발견하고 고칠 수 있게 해줍니다. 또한 디버거는 호출스택의 가장 아랫단까지의 모든 단계를 확인할 수 있게 해 줍니다.

- 개발적 입장에서, 노트북에서 개발된 동일한 코드를 그대로 배포할 수 있습니다. 딥러닝 서버만이 이해할 수 있는 다른 불가사의한 형태로 변환할 필요가 없습니다.

## 결론

교육적 입장에서, 우리가 집중하고자 하는것은 항상 딥러닝의 개념을 설명하고, 툴을 사용해서 실제로 실현할 수 있게끔 하는것입니다. 저희는 학생들이 기초만 잘 이해한다면 다른 언어로 갈아타는것이 생산적이도록 매우 쉽게 만들어준다는것과 실제 문제를 해결하는데 적용하기에 매우 쉽게 해준다는것을 알게 되었습니다.

저희의 Python fastai 라이브러리는 여전히 개발과 교육에 집중하게될 것입니다. 하지만, S4TF를 사용한 많은 연구를 할 것이고, 그것이 가진 잠재성에 도달한다고 생각될때, 미래에 있을 강의에 더욱 자주 등장하게될 것입니다! Swift를 이용한 실용적이고 세계적 수준의 딥러닝에 접근을 손쉽게 만들 생각입니다. - 그리고, fastai(또는 뭔가 더 좋은것)를 swift로 전환함을 의미할지도 모릅니다. 정확히 어떤것일지 이야기하기엔 너무 이릅니다. 이 모든것이 실현되는데 일조하고 싶다면, 다가오는 클래스에 샌프란시스코 대학에서 [직접](https://www.usfca.edu/data-institute/certificates/deep-learning-part-two) 또는 파트2 [MOOC](https://course.fast.ai/)(2019/06)에 참여해 주시기 바랍니다.

